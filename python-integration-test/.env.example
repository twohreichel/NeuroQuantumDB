# Environment variables for NeuroQuantumDB Integration Tests

# API Configuration
NEUROQUANTUM_API_URL=http://localhost:8080
NEUROQUANTUM_API_KEY=

# Test Configuration
TEST_TIMEOUT=30
MAX_RETRIES=3
RETRY_DELAY=1.0

# Data Generation Settings
NUM_CUSTOMERS=1000
NUM_PRODUCTS=200
NUM_ORDERS=5000
NUM_BIOMETRIC_RECORDS=1000

# Performance Testing
BENCHMARK_ITERATIONS=100
BENCHMARK_WARMUP=10

# Logging
LOG_LEVEL=INFO
"""Performance benchmark tests."""

import pytest
from src.client import NeuroQuantumClient


@pytest.mark.performance
class TestPerformance:
    """Performance benchmark tests."""

    @pytest.mark.benchmark
    async def test_simple_select_performance(
        self,
        client: NeuroQuantumClient,
        benchmark
    ):
        """Benchmark simple SELECT query."""
        async def run_query():
            return await client.execute_query(
                "SELECT * FROM customers LIMIT 100"
            )

        result = await run_query()
        assert result.success

    async def test_join_performance(self, client: NeuroQuantumClient):
        """Test JOIN query performance."""
        result = await client.execute_query("""
            SELECT c.name, o.order_id, p.name
            FROM customers c
            JOIN orders o ON c.customer_id = o.customer_id
            JOIN products p ON o.product_id = p.product_id
            LIMIT 100
        """)

        assert result.success
        # JOIN should complete in reasonable time
        assert result.execution_time_ms < 2000

    async def test_aggregation_performance(self, client: NeuroQuantumClient):
        """Test aggregation query performance."""
        result = await client.execute_query("""
            SELECT country, COUNT(*) as count, AVG(age) as avg_age
            FROM customers
            GROUP BY country
        """)

        assert result.success
        # Aggregation should complete in reasonable time
        assert result.execution_time_ms < 1500

    async def test_large_result_set_performance(self, client: NeuroQuantumClient):
        """Test performance with large result set."""
        result = await client.execute_query(
            "SELECT * FROM orders LIMIT 1000"
        )

        assert result.success
        assert result.rows_returned <= 1000
        # Should handle 1000 rows efficiently
        assert result.execution_time_ms < 3000

    @pytest.mark.slow
    async def test_concurrent_queries(self, client: NeuroQuantumClient):
        """Test concurrent query execution."""
        import asyncio

        queries = [
            "SELECT * FROM customers LIMIT 10",
            "SELECT * FROM products LIMIT 10",
            "SELECT * FROM orders LIMIT 10",
        ]

        # Execute queries concurrently
        results = await asyncio.gather(*[
            client.execute_query(q) for q in queries
        ])

        # All should succeed
        assert all(r.success for r in results)

        # Total time should be less than sequential execution
        total_time = sum(r.execution_time_ms for r in results)
        assert total_time < 5000

