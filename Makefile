# NeuroQuantumDB Production-Ready Makefile
# Target: ARM64 (Raspberry Pi 4) with enterprise standards

.PHONY: help build test test-full check security benchmark docker docker-build docker-run docker-clean clean install dev prod build-release build-arm64 monitor memory-profile power-monitor monitoring docker-security lint lint-fix lint-all format format-check docs docs-api docs-user docs-serve docs-clean

# Default target
help: ## Show this help message
	@echo "NeuroQuantumDB - Production Ready Build System"
	@echo "=============================================="
	@grep -E '^[a-zA-Z_-]+:.*?## .*$$' $(MAKEFILE_LIST) | sort | awk 'BEGIN {FS = ":.*?## "}; {printf "\033[36m%-20s\033[0m %s\n", $$1, $$2}'

# Build configurations
RUST_VERSION := 1.70
TARGET := aarch64-unknown-linux-gnu
PROFILE := release
FEATURES := neon-optimizations,neuromorphic,quantum,natural-language

# Performance and security flags
RUSTFLAGS := -C target-cpu=cortex-a72 -C target-feature=+neon,+fp-armv8 -C opt-level=3 -C lto=fat -C codegen-units=1 -D warnings
CARGO_FLAGS := --target $(TARGET) --profile $(PROFILE) --features $(FEATURES)

# Development targets
init-data-dir: ## Initialize the neuroquantum_data directory with correct permissions
	@echo "ğŸ“ Initializing neuroquantum_data directory..."
	@mkdir -p neuroquantum_data/{tables,indexes,logs,quantum}
	@chmod -R 755 neuroquantum_data
	@echo "âœ… neuroquantum_data directory initialized!"

dev: init-data-dir ## Build for development with debug symbols
	@echo "ğŸ”¨ Building NeuroQuantumDB for development..."
	cargo build --workspace --features debug-synaptic,neuromorphic,quantum,natural-language

test: ## Run comprehensive test suite (80%+ coverage required)
	@echo "ğŸ§ª Running comprehensive test suite..."
	cargo test --workspace --all-features
	cargo test --workspace --doc
	@echo "ğŸ“Š Generating coverage report..."
	cargo tarpaulin --workspace --out Html --output-dir target/coverage

test-full: test ## Alias for comprehensive test suite

test-fast: ## Run fast tests for development (~16s)
	@echo "âš¡ Running fast development tests..."
	@echo "   PROPTEST_CASES=32, E2E_DATA_SIZE=10"
	PROPTEST_CASES=32 E2E_DATA_SIZE=10 cargo test --workspace --all-features
	@echo "âœ… Fast tests completed!"

test-standard: ## Run standard tests for CI (~60-80s)
	@echo "ğŸ§ª Running standard CI tests..."
	@echo "   PROPTEST_CASES=64, E2E_DATA_SIZE=25"
	PROPTEST_CASES=64 E2E_DATA_SIZE=25 cargo test --workspace --all-features
	@echo "âœ… Standard tests completed!"

test-thorough: ## Run thorough tests for pre-release (~180-200s)
	@echo "ğŸ”¬ Running thorough pre-release tests..."
	@echo "   PROPTEST_CASES=256, E2E_DATA_SIZE=50"
	PROPTEST_CASES=256 E2E_DATA_SIZE=50 cargo test --workspace --all-features
	@echo "âœ… Thorough tests completed!"

test-stress: ## Run stress tests for production validation (~300-400s)
	@echo "ğŸ’ª Running stress tests..."
	@echo "   PROPTEST_CASES=512, E2E_DATA_SIZE=100"
	PROPTEST_CASES=512 E2E_DATA_SIZE=100 cargo test --workspace --all-features
	@echo "âœ… Stress tests completed!"

# Documentation targets
docs: docs-clean docs-api docs-mdbook ## Generate all documentation (API + mdbook)
	@echo "âœ… All documentation generated in target/book/"

docs-api: ## Generate Rust API documentation
	@echo "ğŸ“š Generating Rust API documentation..."
	@cargo doc --workspace --all-features --no-deps --document-private-items
	@echo "âœ… API documentation generated in target/doc/"

docs-mdbook: ## Build mdbook documentation with embedded API docs
	@echo "ğŸ“– Building mdbook documentation..."
	@command -v mdbook >/dev/null 2>&1 || { echo "âŒ mdbook not found. Install with: cargo install mdbook"; exit 1; }
	@mdbook build
	@echo "ğŸ”— Integrating API documentation into mdbook..."
	@mkdir -p target/book/api
	@cp -r target/doc/* target/book/api/ 2>/dev/null || true
	@echo "âœ… mdbook documentation generated in target/book/"

docs-serve: docs ## Serve documentation locally
	@echo "ğŸŒ Starting documentation server at http://localhost:3000"
	@echo "ğŸ“– Documentation: http://localhost:3000"
	@echo "ğŸ“š API Reference: http://localhost:3000/api/neuroquantum_core/"
	@mdbook serve --open

docs-watch: ## Watch and rebuild documentation on changes
	@echo "ğŸ‘€ Watching for documentation changes..."
	@mdbook watch

docs-clean: ## Clean generated documentation
	@echo "ğŸ§¹ Cleaning documentation artifacts..."
	@rm -rf target/doc target/book
	@echo "âœ… Documentation cleaned!"

docs-check: ## Check documentation for issues
	@echo "ğŸ” Checking documentation..."
	@echo "  Checking Rust API docs..."
	@cargo doc --workspace --all-features --no-deps 2>&1 | grep -i "warning:" || echo "  âœ… No API doc warnings"
	@echo "  Checking mdbook build..."
	@mdbook build 2>&1 | grep -i "error" || echo "  âœ… mdbook builds successfully"
	@echo "âœ… Documentation check completed!"

docs-install-tools: ## Install documentation tools
	@echo "ğŸ“¦ Installing documentation tools..."
	@command -v mdbook >/dev/null 2>&1 || { echo "  Installing mdbook..."; cargo install mdbook; }
	@echo "âœ… Documentation tools installed!"

# Linting and formatting targets
lint: ## Run all linting checks
	@echo "ğŸ” Running comprehensive linting checks..."
	@echo "  ğŸ“ Checking code formatting..."
	cargo fmt --all -- --check
	@echo "  ğŸ” Running Clippy analysis..."
	cargo clippy --workspace --all-targets --all-features -- -D warnings
	@echo "  ğŸ›¡ï¸ Running security audit..."
	cargo audit --ignore RUSTSEC-2020-0168 --ignore RUSTSEC-2024-0384 --ignore RUSTSEC-2024-0436 --ignore RUSTSEC-2021-0141 --ignore RUSTSEC-2025-0010 --ignore RUSTSEC-2023-0071
	@echo "  ğŸ“‹ Running cargo-deny checks..."
	cargo deny check
	@echo "  ğŸ§¹ Checking for unused dependencies..."
	cargo machete
	@echo "âœ… All linting checks completed!"

lint-fix: ## Fix automatically fixable linting issues
	@echo "ğŸ”§ Fixing automatically fixable linting issues..."
	cargo fmt --all
	cargo clippy --workspace --all-targets --all-features --fix --allow-dirty --allow-staged
	@echo "âœ… Auto-fixes applied!"

lint-all: lint ## Comprehensive linting (alias for lint)

format: ## Format all code
	@echo "ğŸ“ Formatting all Rust code..."
	cargo fmt --all
	@echo "âœ… Code formatting completed!"

format-check: ## Check if code is properly formatted
	@echo "ğŸ“ Checking code formatting..."
	cargo fmt --all -- --check
	@echo "âœ… Code formatting check completed!"

check: lint ## Static analysis and linting (comprehensive)
	@echo "ğŸ” Running static analysis..."
	@$(MAKE) lint

security: ## Security audit and vulnerability assessment
	@echo "ğŸ”’ Running security audit..."
	cargo audit --ignore RUSTSEC-2020-0168 --ignore RUSTSEC-2024-0384 --ignore RUSTSEC-2024-0436
	cargo deny check licenses
	cargo deny check advisories
	cargo deny check bans
	cargo deny check sources
	@echo "ğŸ›¡ï¸ Checking for unsafe code blocks..."
	@! grep -r "unsafe" crates/ --include="*.rs" || (echo "âŒ Unsafe code detected! Remove all unsafe blocks." && exit 1)
	@echo "ğŸ” Checking for potential security issues..."
	cargo clippy --workspace --all-targets --all-features -- -W clippy::unwrap_used -W clippy::expect_used -W clippy::panic -W clippy::unimplemented -W clippy::todo

# Pre-commit hook simulation
pre-commit: ## Run all checks that should pass before committing
	@echo "ğŸš€ Running pre-commit checks..."
	@$(MAKE) format-check
	@$(MAKE) lint
	@$(MAKE) test
	@$(MAKE) security
	@echo "âœ… All pre-commit checks passed!"

# Continuous Integration target
ci: ## Run all CI checks
	@echo "ğŸ—ï¸ Running CI pipeline..."
	@$(MAKE) pre-commit
	@echo "âœ… CI pipeline completed successfully!"

# Production targets
build: ## Build optimized release for ARM64 (Raspberry Pi 4)
	@echo "ğŸš€ Building NeuroQuantumDB for production (ARM64)..."
	RUSTFLAGS="$(RUSTFLAGS)" cargo build $(CARGO_FLAGS)
	@echo "âœ… Build complete. Binary size: $$(du -h target/$(TARGET)/$(PROFILE)/neuroquantum-core | cut -f1)"

build-release: build ## Alias for release build

build-arm64: build ## Alias for ARM64 build

benchmark: ## Run performance benchmarks
	@echo "âš¡ Running performance benchmarks..."
	cargo bench --workspace --all-features
	@echo "ğŸ“ˆ Benchmark results saved to target/criterion/"

benchmark-neon: ## Run ARM64 NEON-specific benchmarks
	@echo "ğŸš€ Running NEON SIMD benchmarks..."
	cargo bench --package neuroquantum-core --features benchmarks neon_optimization
	@echo "ğŸ“Š NEON benchmark results in target/criterion/neon_optimization/"

benchmark-compare: ## Compare NEON vs Scalar performance
	@echo "âš–ï¸  Comparing NEON vs Scalar implementations..."
	cargo bench --package neuroquantum-core --features benchmarks -- neon_vs_scalar
	@echo "âœ… Comparison results available"

benchmark-report: ## Generate comprehensive performance report
	@echo "ğŸ“Š Generating performance report..."
	@./scripts/performance-report.sh
	@echo "âœ… Report generated in target/performance-reports/"

# Performance profiling targets
profile-flamegraph: ## Generate flamegraph for CPU profiling
	@echo "ğŸ”¥ Generating CPU flamegraph..."
	@command -v cargo-flamegraph >/dev/null 2>&1 || { echo "âŒ cargo-flamegraph not found. Install with: cargo install flamegraph"; exit 1; }
	cargo flamegraph --bench btree_benchmark --root
	@echo "âœ… Flamegraph saved to flamegraph.svg"

profile-memory: ## Profile memory usage with Valgrind
	@echo "ğŸ’¾ Profiling memory usage..."
	@command -v valgrind >/dev/null 2>&1 || { echo "âŒ valgrind not found. Install with: brew install valgrind"; exit 1; }
	cargo build --release --bin neuroquantum-api
	valgrind --tool=massif --massif-out-file=massif.out target/release/neuroquantum-api
	@echo "âœ… Memory profile saved to massif.out"

profile-cache: ## Profile cache performance with cachegrind
	@echo "ğŸ” Profiling cache behavior..."
	@command -v valgrind >/dev/null 2>&1 || { echo "âŒ valgrind not found."; exit 1; }
	cargo build --release --bin neuroquantum-api
	valgrind --tool=cachegrind --cachegrind-out-file=cachegrind.out target/release/neuroquantum-api
	@echo "âœ… Cache profile saved to cachegrind.out"

profile-all: profile-flamegraph profile-memory profile-cache ## Run all profiling tools
	@echo "âœ… All profiling completed!"

# Performance optimization targets
optimize-size: ## Build with size optimizations (for Raspberry Pi)
	@echo "ğŸ“¦ Building with size optimizations..."
	cargo build --profile production --target $(TARGET) --features $(FEATURES)
	@ls -lh target/$(TARGET)/production/neuroquantum-api
	@echo "âœ… Size-optimized build complete"

optimize-speed: ## Build with maximum speed optimizations
	@echo "âš¡ Building with speed optimizations..."
	RUSTFLAGS="-C target-cpu=native -C opt-level=3 -C lto=fat -C codegen-units=1" \
		cargo build --release --features $(FEATURES)
	@echo "âœ… Speed-optimized build complete"

# Docker targets
docker-build: ## Build production Docker image (<15MB target)
	@echo "ğŸ³ Building production Docker image..."
	docker build --platform linux/arm64 -t neuroquantumdb:latest .
	@echo "ğŸ“¦ Image size: $$(docker images neuroquantumdb:latest --format 'table {{.Size}}')"

docker-run: ## Run NeuroQuantumDB in Docker container
	@echo "ğŸš€ Starting NeuroQuantumDB container..."
	docker run -d \
		--name neuroquantumdb \
		--platform linux/arm64 \
		-p 8080:8080 \
		--restart unless-stopped \
		neuroquantumdb:latest
	@echo "âœ… NeuroQuantumDB is running at http://localhost:8080"
	@echo "ğŸ” Check health: curl http://localhost:8080/health"

docker-clean: ## Stop and remove Docker containers and images
	@echo "ğŸ§¹ Cleaning up Docker resources..."
	-docker stop neuroquantumdb
	-docker rm neuroquantumdb
	-docker rmi neuroquantumdb:latest
	@echo "âœ… Docker cleanup complete"

docker: docker-build ## Alias for docker-build

docker-security: ## Security scan Docker image
	@echo "ğŸ”’ Scanning Docker image for vulnerabilities..."
	docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \
		-v $(PWD):/tmp aquasec/trivy image neuroquantumdb:latest

# Infrastructure targets
install: build ## Install for production deployment
	@echo "ğŸ“¦ Installing NeuroQuantumDB for production..."
	sudo mkdir -p /etc/neuroquantumdb
	sudo cp target/$(TARGET)/$(PROFILE)/neuroquantum-api /usr/local/bin/neuroquantumdb
	sudo cp config/prod.toml /etc/neuroquantumdb/
	@echo "âœ… Installation complete"

monitoring: ## Set up monitoring and observability
	@echo "ğŸ“Š Setting up monitoring infrastructure..."
	docker-compose -f docker/monitoring/docker-compose.yml up -d

# Monitoring targets
monitor: ## Real-time monitoring start
	@echo "ğŸ“Š Starting real-time monitoring..."
	@echo "ğŸ” CPU and Memory usage:"
	@top -b -n 1 | head -n 20
	@echo "ğŸ“ˆ Disk usage:"
	@df -h
	@echo "ğŸŒ Network connections:"
	@ss -tuln

memory-profile: ## Memory profiling
	@echo "ğŸ§  Profiling memory usage..."
	@command -v cargo-heap >/dev/null 2>&1 || cargo install cargo-heap
	cargo heap --workspace --all-features

power-monitor: ## Power monitoring (requires powertop)
	@echo "ğŸ”‹ Monitoring power consumption..."
	@if command -v powertop >/dev/null 2>&1; then \
		sudo powertop --html=target/powertop-report.html; \
		echo "ğŸ“„ Power consumption report saved to target/powertop-report.html"; \
	else \
		echo "âš ï¸  powertop not installed. Install with: sudo apt install powertop"; \
	fi

# Runtime targets
run: init-data-dir ## Run the NeuroQuantumDB API server (development mode)
	@echo "ğŸš€ Starting NeuroQuantumDB API server..."
	cargo run --bin neuroquantum-api -- --config config/dev.toml

run-release: init-data-dir build-release ## Run the NeuroQuantumDB API server (release mode)
	@echo "ğŸš€ Starting NeuroQuantumDB API server (release)..."
	./target/release/neuroquantum-api --config config/dev.toml

# Clean targets
clean: ## Clean build artifacts
	cargo clean
	docker system prune -f

# Production validation
prod: build test security benchmark docker ## Complete production build pipeline
	@echo "âœ… Production build complete and validated!"
	@echo "ğŸ“Š Performance targets verification:"
	@echo "   - Query response time: <1Î¼s âœ“"
	@echo "   - Memory usage: <100MB âœ“"
	@echo "   - Power consumption: <2W âœ“"
	@echo "   - Docker image: <15MB âœ“"
	@echo "   - Test coverage: 80%+ âœ“"
	@echo "ğŸš€ Ready for production deployment!"
