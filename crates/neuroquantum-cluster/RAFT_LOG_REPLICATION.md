# Raft Log Replication Implementation

## Overview

This implementation provides complete Raft log replication functionality for the NeuroQuantumDB cluster module, enabling reliable data consistency across distributed nodes through leader-based consensus.

## Architecture

### Components

#### 1. Leader-Side Replication
- **next_index**: Tracks the next log entry to send to each follower
- **match_index**: Tracks the highest log entry known to be replicated on each follower
- **Heartbeat Integration**: AppendEntries RPCs are sent periodically as heartbeats
- **Parallel Replication**: Sends AppendEntries to all followers concurrently

#### 2. Follower-Side Processing
- **Log Consistency Check**: Validates prevLogIndex and prevLogTerm before accepting entries
- **Conflict Detection**: Identifies and resolves log inconsistencies
- **Commit Index Update**: Updates local commit index based on leader's commitIndex
- **Entry Application**: Applies committed entries to the state machine

#### 3. Conflict Resolution
- **Backtracking**: Decrements next_index when AppendEntries fails
- **Optimization Hints**: Uses conflict_index and conflict_term for faster catchup
- **Fast Recovery**: Quickly brings followers up-to-date after partitions

## Implementation Details

### Protobuf Enhancements

```protobuf
message AppendEntriesResponse {
    uint64 term = 1;
    bool success = 2;
    uint64 last_log_index = 3;
    // Optimization hints for faster catchup
    optional uint64 conflict_index = 4;
    optional uint64 conflict_term = 5;
}
```

### Key Methods

#### `replicate_to_follower(follower_id: NodeId)`
Sends AppendEntries RPC to a specific follower with appropriate entries based on next_index.

#### `handle_append_entries(request: AppendEntriesRequest)`
Processes incoming AppendEntries RPC on follower side:
1. Validates term
2. Checks log consistency
3. Appends/overwrites entries
4. Updates commit index

#### `handle_append_entries_response(follower_id, response)`
Processes AppendEntries response on leader side:
1. Updates next_index and match_index
2. Handles backtracking on failures
3. Advances commit index when majority replicates

#### `try_advance_commit_index()`
Determines if commit index can be advanced:
- Counts replicas with match_index >= N
- Checks for majority quorum
- Only commits entries from current term (Raft safety rule)

### Raft Safety Rules

The implementation adheres to Raft's safety guarantees:

1. **Leader Append-Only**: Leaders never overwrite or delete entries in their log
2. **Log Matching**: If two logs contain an entry with the same index and term, then the logs are identical in all entries up through that index
3. **Leader Completeness**: If a log entry is committed in a given term, that entry will be present in the logs of the leaders for all higher-numbered terms
4. **State Machine Safety**: If a server has applied a log entry at a given index to its state machine, no other server will ever apply a different log entry for the same index

### Commit Rules (ยง5.4.2)

- A leader can only directly commit entries from its current term
- Once a current-term entry is committed, all previous entries are implicitly committed
- This prevents committed entries from being overwritten by new leaders

## Usage Example

```rust
use neuroquantum_cluster::{RaftConsensus, NetworkTransport, ClusterConfig};
use std::sync::Arc;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // Create network transport
    let config = ClusterConfig::default();
    let transport = Arc::new(NetworkTransport::new(&config).await?);
    
    // Create consensus module
    let consensus = RaftConsensus::new(1, transport, config).await?;
    consensus.start().await?;
    
    // Promote to leader (in real deployment, via election)
    consensus.promote_to_leader().await?;
    
    // Initialize replication to followers
    consensus.initialize_replication_state(vec![2, 3]).await;
    
    // Propose new entries
    let index = consensus.propose(b"my_data".to_vec()).await?;
    println!("Entry appended at index: {}", index);
    
    // Apply committed entries
    let applied = consensus.apply_committed_entries().await?;
    println!("Applied {} entries to state machine", applied);
    
    Ok(())
}
```

## Testing

### Integration Tests (13 tests)
- Basic log replication
- AppendEntries success/failure scenarios
- Log consistency checks
- Conflict detection and resolution
- Commit index advancement
- Entry application to state machine

### Chaos Tests (10 tests)
- Follower crash and recovery
- Network partitions and catchup
- Leader failures
- Split-brain prevention with fencing tokens
- Majority commit with node failures
- Concurrent proposals under load
- Multi-term log consistency
- Rapid leader changes
- Election timeout during replication

## Performance Considerations

1. **Parallel Replication**: AppendEntries sent to all followers concurrently
2. **Fast Catchup**: Conflict hints minimize round trips during recovery
3. **Batching**: Multiple log entries sent in single AppendEntries RPC
4. **Heartbeat Integration**: No separate heartbeat mechanism needed

## Security Features

1. **Fencing Tokens**: Prevents split-brain scenarios
2. **Term Validation**: Rejects stale requests from old leaders
3. **Quorum Checks**: Ensures majority agreement before committing
4. **Lease-Based Leadership**: Prevents concurrent leaders

## Limitations and Future Work

1. **Snapshot Transfer**: Not yet implemented (InstallSnapshot RPC is stub)
2. **Log Compaction**: Not yet implemented
3. **Pre-vote Optimization**: Could reduce disruptions during network partitions
4. **Pipeline Replication**: Could improve throughput
5. **Persistent Storage**: Currently in-memory only
6. **Network Layer Integration**: Full end-to-end RPC handling needs completion

## References

- [In Search of an Understandable Consensus Algorithm (Extended Version)](https://raft.github.io/raft.pdf)
- Raft Paper Section 5.3: Log Replication
- Raft Paper Section 5.4.2: Committing entries from previous terms

## Contributing

When extending this implementation, please ensure:
1. All new code includes comprehensive tests
2. Raft safety properties are maintained
3. Error handling follows existing patterns
4. Logging is appropriate for debugging
5. Documentation is updated accordingly
